
# Release Notes worksheet inductor

The main goal of this process is to rephrase all the commit messages below to make them **clear and easy to read** by the end user. You should follow the following instructions to do so:

* **Please clean up and format commit titles to be readable by the general PyTorch user.** Make sure you're [following the guidance here](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit)! Your resulting notes must be consistent and easy to read.
* Please sort commits into the following categories (you should not rename the categories!), I tried to pre-sort these to ease your work, feel free to move commits around if the current categorization is not good.
* Anything that is not public facing needs to be removed.
* If anything is miscategorized/belongs to another domain, move it to `miscategorized.md`.
* Please scan through `miscategorized.md` and handle any commits that belong within your domain according to these instructions.
* We place a lot of emphasis on the “BC-breaking” and “deprecation” sections. Those should be where the most effort goes in. The “improvements” and “bug fixes” for Python API should be nice as well.
* Once you are finished, move this very file from `todo/` to `done/` and submit a pull request.

The categories below are as follows:

* BC breaking: All commits that are BC-breaking. These are the most important commits. If any pre-sorted commit is actually BC-breaking, do move it to this section. Each commit should contain a paragraph explaining the rational behind the change as well as an example for how to update user code [BC-Guidelines](https://docs.google.com/document/d/14OmgGBr1w6gl1VO47GGGdwrIaUNr92DFhQbY_NEk8mQ/edit#heading=h.a9htwgvvec1m).
* Deprecations: All commits introducing deprecation. Each commit should include a small example explaining what should be done to update user code.
* new_features: All commits introducing a new feature (new functions, new submodule, new supported platform etc)
* improvements: All commits providing improvements to existing feature should be here (new backend for a function, new argument, better numerical stability)
* bug fixes: All commits that fix bugs and behaviors that do not match the documentation
* performance: All commits that are added mainly for performance (we separate this from improvements above to make it easier for users to look for it)
* documentation: All commits that add/update documentation
* Developers: All commits that are not end-user facing but still impact people that compile from source, develop into pytorch, extend pytorch, etc
* not user facing: All commits that are not public end-user facing and hence should be dropped from the release notes

## inductor
### bc breaking
### deprecation
 - Deprecated: `rocm.n_max_profiling_configs`. Instead, use ck-tile based configs `rocm.ck_max_profiling_configs` and `rocm.ck_tile_max_profiling_configs`. ([#152341](https://github.com/pytorch/pytorch/pull/152341))
 - Deprecated: `autotune_fallback_to_aten`. Inductor will no longer silently fall back to `ATen`. Please add `"ATEN"` to `max_autotune_gemm_backends` for the old behavior. ([#154331](https://github.com/pytorch/pytorch/pull/154331))
 - Deprecated: `use_mixed_mm` and `mixed_mm_choice`. Torch Inductor now supports prologue fusion, so there is no need for special cases now. ([#152071](https://github.com/pytorch/pytorch/pull/152071))
 - Rename `aot_inductor.embed_cubin` to `aot_inductor.embed_kernel_binary`. ([#154412](https://github.com/pytorch/pytorch/pull/154412))
 - Remove the `aot_inductor.emit_current_arch_binary` option. ([#155768](https://github.com/pytorch/pytorch/pull/155768))
 - `custom_op_default_layout_constraint` moved from inductor config to functorch config. ([#148104](https://github.com/pytorch/pytorch/pull/148104))
 - Config `aot_inductor.compile_wrapper_with_O0` changed to `compile_wrapper_opt_level`. ([#148714](https://github.com/pytorch/pytorch/pull/148714))
- Deprecated: `inductor.config.descriptive_names = False`. Use one of the other available options. ([#151481](https://github.com/pytorch/pytorch/pull/151481))
### new features
- We can now map a Dynamo graph to multiple different Inductor graphs, which can be optimized separaetly. ([#147648](https://github.com/pytorch/pytorch/pull/147648)) ([#147038](https://github.com/pytorch/pytorch/pull/147038))
- Add config to specify custom op C shim: `aot_inductor.custom_ops_to_c_shims` and `aot_inductor.custom_op_libs`. ([#153968](https://github.com/pytorch/pytorch/pull/153968))
- Add AOTI model name config `aot_inductor.model_name_for_generated_files`. ([#154129](https://github.com/pytorch/pytorch/pull/154129))
- New config to limit fusions to a node distance of 64: `max_fusion_buffer_group_pairwise_attempts`. ([#154688](https://github.com/pytorch/pytorch/pull/154688))
- Add config control for CUTLASS operation selection: `cuda.cutlass_enabled_ops`. ([#155770](https://github.com/pytorch/pytorch/pull/155770))
- Add config `triton.cudagraph_capture_sizes` to specify dynamic shapes to capture cudagraphs and skip cudagraph for other shapes. ([#156551](https://github.com/pytorch/pytorch/pull/156551))
- New config `use_static_cuda_launcher` to launch compiled Triton statically to improve cold start times. ([#148890](https://github.com/pytorch/pytorch/pull/148890))
- New config `assume_unaligned_fallback_output` to allow inductor to track unaligned outputs. ([#150777](https://github.com/pytorch/pytorch/pull/150777))
- New config `cuda.cutlass_tma_only` controls whether or not to only use TMA-compatible kernels in CUTLASS. ([#152815](https://github.com/pytorch/pytorch/pull/152815))
- Add config `static_launch_user_defined_triton_kernels` to statically launch user defined triton kernels. ([#153725](https://github.com/pytorch/pytorch/pull/153725))
- New config `precompilation_timeout_seconds` to control the timeout on precompilation. ([#153788](https://github.com/pytorch/pytorch/pull/153788))
- New config `disable_decompose_k` to disable new  DecomposeK GEMM Kernels. ([#154421](https://github.com/pytorch/pytorch/pull/154421))
- New config `_post_fusion_custom_pass` to register a custom pass to be run right after fusion in Inductor Scheduler. ([#153723](https://github.com/pytorch/pytorch/pull/153723))
- New config `min_num_split` sets the minimum number of splits in a split reduction. ([#155941](https://github.com/pytorch/pytorch/pull/155941))
- New config `max_autotune_flex_search_space` allows specifying the size of the search space for flex attention autotuning. ([#156307](https://github.com/pytorch/pytorch/pull/156307))
- Add block sparse for FlexAttention CPU. ([#147196](https://github.com/pytorch/pytorch/pull/147196))
- Add GEMM templates for _weight_int4pack_mm_for_cpu with AMX. ([#150603](https://github.com/pytorch/pytorch/pull/150603))
### improvements
- Add num_runners to AOTIModelPackageLoader. ([#149364](https://github.com/pytorch/pytorch/pull/149364))
- New script `profile_analysis.py` to diff kernel usage from `torch.profile` traces. ([#149697](https://github.com/pytorch/pytorch/pull/149697))
- Improvements on CPU welford reduction. ([#145061](https://github.com/pytorch/pytorch/pull/145061))
- New environement var `LOG_AUTOTUNE_RESULTS` for autotune log. ([#156254](https://github.com/pytorch/pytorch/pull/156254))
### bug fixes
- Support special kwargs in AMD triton configs. ([#154605](https://github.com/pytorch/pytorch/pull/154605))
- Fix minifier when one has multiple Python runtimes. ([#155918](https://github.com/pytorch/pytorch/pull/155918))
- Bug fix for int8 GEMM compensation epilogue. ([#152408](https://github.com/pytorch/pytorch/pull/152408))
### performance
- Support Graph Partitioning on custom ops. ([#149782](https://github.com/pytorch/pytorch/pull/149782))
- New AMD specific GEMM Configs. ([#147315](https://github.com/pytorch/pytorch/pull/147315))
- Add pack support and use micro gemm for Half Flex Attention on CPU. ([#151530](https://github.com/pytorch/pytorch/pull/151530))
- Enable a config `cpp.use_small_dequant_buffer` to use a small dequant buffer for woq int4. ([#156395](https://github.com/pytorch/pytorch/pull/156395))
- Faster int8 WoQ GEMM for small M with explicit prefetching and different outer loops. ([#149373](https://github.com/pytorch/pytorch/pull/149373))
- Improve A16W4 GEMM template performance by using block_n=32. ([#156174](https://github.com/pytorch/pytorch/pull/156174))
- Use AMX-based microkernels when M > 4 for GEMM template for INT4 weight. ([#155444](https://github.com/pytorch/pytorch/pull/155444))
- Optimize the heuristics of parallel reduction on CPU. ([#149614](https://github.com/pytorch/pytorch/pull/149614))
- Set prop_kind to forward_inference when grad is not needed for `mkldnn_linear_pointwise` and `mkldnn_convolution_pointwise`. ([#147072](https://github.com/pytorch/pytorch/pull/147072))
### docs
### devs
### Untopiced
- Fix sympy float priting ([#147552](https://github.com/pytorch/pytorch/pull/147552))
- partitioner: treat inputs with static indices as free to save ([#148922](https://github.com/pytorch/pytorch/pull/148922))
- [Inductor][Optimus] split cat aten pass ([#149027](https://github.com/pytorch/pytorch/pull/149027))
- [Inductor][Optimus] Add move view after cat aten pattern ([#149178](https://github.com/pytorch/pytorch/pull/149178))
- [inductor] Add a helper for convert index_dtype to torch dtype ([#149531](https://github.com/pytorch/pytorch/pull/149531))
- [inductor] support dilation in max_pool2d lowering ([#148209](https://github.com/pytorch/pytorch/pull/148209))
- [inductor] Fix division by zero error in fractional max ([#148729](https://github.com/pytorch/pytorch/pull/148729))
- [Graph Partition] Support symbol inputs ([#149458](https://github.com/pytorch/pytorch/pull/149458))
- [graph partition] support splitting on custom ops ([#149782](https://github.com/pytorch/pytorch/pull/149782))
- [aoti] Better error message when torchbind object is used as a graph input in AOTI ([#149965](https://github.com/pytorch/pytorch/pull/149965))
- Change arg_kwarg_vals propagation strategy ([#148046](https://github.com/pytorch/pytorch/pull/148046))
- Add needs_exact_strides operator tag for Inductor to force exact strides ([#148063](https://github.com/pytorch/pytorch/pull/148063))
- Implement needs_exact_strides for mutable custom operators ([#148091](https://github.com/pytorch/pytorch/pull/148091))
- Rename node.meta["arg_kwarg_vals"] to node.meta["eager_input_vals"] ([#148092](https://github.com/pytorch/pytorch/pull/148092))
- Fix log2, PowByNatural printing ([#147592](https://github.com/pytorch/pytorch/pull/147592))
- [inductor] Lowerings for max_pool3d ([#148210](https://github.com/pytorch/pytorch/pull/148210))
- [aoti] make a check function for each input ([#150553](https://github.com/pytorch/pytorch/pull/150553))
- [inductor][autotune cache] add torch_key() to configs hash ([#150494](https://github.com/pytorch/pytorch/pull/150494))
- [AOTI] Always use oss schema for ExternKernelNodes serialization ([#150197](https://github.com/pytorch/pytorch/pull/150197))
- [ROCm] Introduce AMD specific inductor gemm tuning  ([#147315](https://github.com/pytorch/pytorch/pull/147315))
- Support negative values for fill with uint tensors ([#144458](https://github.com/pytorch/pytorch/pull/144458))
- Back out "[AOTI] Always use oss schema for ExternKernelNodes serialization" ([#151026](https://github.com/pytorch/pytorch/pull/151026))
- [Inductor] add support for disabling atomic adds ([#151033](https://github.com/pytorch/pytorch/pull/151033))
- [Cutlass] Import cutlass python API for EVT ([#150344](https://github.com/pytorch/pytorch/pull/150344))
- [Cutlass] Codegen for EVT Epilogue ([#150345](https://github.com/pytorch/pytorch/pull/150345))
- [Cutlass] Integrate EVT codegen into 3x gemm template ([#150346](https://github.com/pytorch/pytorch/pull/150346))
- [graph partition] reorder to reduce #partitions for simple dependencies ([#150814](https://github.com/pytorch/pytorch/pull/150814))
- Fix tensor_constant name collision in aot_export_module ([#151123](https://github.com/pytorch/pytorch/pull/151123))
- [Cutlass] Implement Epilogue Argument emitter ([#150903](https://github.com/pytorch/pytorch/pull/150903))
- Add device check for inputs ([#151828](https://github.com/pytorch/pytorch/pull/151828))
- Package const folded graph's cubin file ([#152145](https://github.com/pytorch/pytorch/pull/152145))
- [inductor] set correct precompile start time ([#152284](https://github.com/pytorch/pytorch/pull/152284))
- [AOTInductor] Propagate ConstantType for main graph. ([#152272](https://github.com/pytorch/pytorch/pull/152272))
- [Cutlass] Remove unused dtype conversion map ([#152305](https://github.com/pytorch/pytorch/pull/152305))
- [Cutlass] Fix int check in example tensor creation ([#152306](https://github.com/pytorch/pytorch/pull/152306))
- [Cutlass] Implement cutlass epilogue visitor python codegen ([#150905](https://github.com/pytorch/pytorch/pull/150905))
- [Cutlass] Fixes for e2e compilation in arg rendering ([#151405](https://github.com/pytorch/pytorch/pull/151405))
- [standalone_compile] fix dynamic shapes with config_patches ([#152462](https://github.com/pytorch/pytorch/pull/152462))
- [Inductor] Fix int check again ([#152576](https://github.com/pytorch/pytorch/pull/152576))
- Support more dtypes for input, indices in gather ([#151822](https://github.com/pytorch/pytorch/pull/151822))
- [cutlass backend] Move cutlass compiled cache to cache_dir ([#151825](https://github.com/pytorch/pytorch/pull/151825))
- consolidate guard_or_x and definitely_x ([#152463](https://github.com/pytorch/pytorch/pull/152463))
- [Inductor] Introduce Wrapper IR line for symbolic call args ([#152587](https://github.com/pytorch/pytorch/pull/152587))
- Add optional device index to AOTIModelPackageLoader ([#152093](https://github.com/pytorch/pytorch/pull/152093))
- [inductor] fix lowering for cummin, cummax for one element tensors ([#151931](https://github.com/pytorch/pytorch/pull/151931))
- [inductor][retry] Realize bucketize/searchsorted output ([#152858](https://github.com/pytorch/pytorch/pull/152858))
- [aoti] skip input symbol codegen for sympy expr w/ many symbols ([#152579](https://github.com/pytorch/pytorch/pull/152579))
- [Cutlass] Handle broadcasting in EVT python codegen ([#152733](https://github.com/pytorch/pytorch/pull/152733))
- [Cutlass] Integrate EVT into CUDACPPScheduling ([#150906](https://github.com/pytorch/pytorch/pull/150906))
- [Cutlass] Add epilogue inputs/outputs to def_kernel ([#151406](https://github.com/pytorch/pytorch/pull/151406))
- [AOTInductor] Generate kernels separately for const graph and main graph ([#153040](https://github.com/pytorch/pytorch/pull/153040))
- [Cutlass] Changes to gemm template for EVT ([#150907](https://github.com/pytorch/pytorch/pull/150907))
- [Cutlass] Implement memory planning for EVT ([#153177](https://github.com/pytorch/pytorch/pull/153177))
- [inductor] dtype promotion error in cat decomp ([#152995](https://github.com/pytorch/pytorch/pull/152995))
- Fix `'TensorBox' object has no attribute 'is_input_buffer'` ([#152980](https://github.com/pytorch/pytorch/pull/152980))
- [reland] Add graph module runtime asserts to AOTI ([#153182](https://github.com/pytorch/pytorch/pull/153182))
- [AOTInductor] Fix clang-tidy warnings in wrapper ([#153197](https://github.com/pytorch/pytorch/pull/153197))
- [AOTI][reland2] Remove typedef for half and bfloat16 ([#153467](https://github.com/pytorch/pytorch/pull/153467))
- Allow to set custom PYTHONPATH for torch.inductor ([#152832](https://github.com/pytorch/pytorch/pull/152832))
- [Cutlass] Enable fusion with FusedSchedulerNodes ([#153588](https://github.com/pytorch/pytorch/pull/153588))
- [PT2][Optimus][Observability] Refactor the logging to avoid excessive tlparse log ([#153584](https://github.com/pytorch/pytorch/pull/153584))
- [aoti] Reset expr when generating cpp code ([#153898](https://github.com/pytorch/pytorch/pull/153898))
- [AOTI][XPU] Embed SPRI-V files into .so ([#153924](https://github.com/pytorch/pytorch/pull/153924))
- [AOTI] Generate unique cubin file names when package_cpp_only ([#153948](https://github.com/pytorch/pytorch/pull/153948))
- [AOTI][reland] Add an option to specify custom op C shim ([#153968](https://github.com/pytorch/pytorch/pull/153968))
- auto functionalize base_hop ([#151067](https://github.com/pytorch/pytorch/pull/151067))
- [Cutlass] Support float8_e4m3fn GEMM ([#153890](https://github.com/pytorch/pytorch/pull/153890))
- [inductor] lowering for fractional_max_pool3d ([#148630](https://github.com/pytorch/pytorch/pull/148630))
- [PT2][Optimus] Fix a typo in decompose_mm ([#154048](https://github.com/pytorch/pytorch/pull/154048))
- [EASY] used guard_or_false instead of guard_sizes_oblivious in pointless_view ([#154154](https://github.com/pytorch/pytorch/pull/154154))
- [BE] Clean up unused parameter input in AOTIModel ([#154276](https://github.com/pytorch/pytorch/pull/154276))
- [AOTI][refactor] Rename embed_cubin to embed_kernel_binary ([#154412](https://github.com/pytorch/pytorch/pull/154412))
- [AOTI] Add a multi_arch_kernel_binary option ([#154413](https://github.com/pytorch/pytorch/pull/154413))
- [Cutlass] Remove spammy log for gemm extensions ([#154548](https://github.com/pytorch/pytorch/pull/154548))
- [AOTI] Save data sizes to constants_info ([#154534](https://github.com/pytorch/pytorch/pull/154534))
- [AOTI][reland] Support multi-arch when using package_cpp_only ([#154608](https://github.com/pytorch/pytorch/pull/154608))
- [AOTI] Support OptionalTensor return type in AOTI proxy executor ([#154286](https://github.com/pytorch/pytorch/pull/154286))
- [flex attention][triton pin] triton_helpers shim for TMA apis ([#154858](https://github.com/pytorch/pytorch/pull/154858))
- [Cutlass] Cleanup gemm_template evt handling ([#154775](https://github.com/pytorch/pytorch/pull/154775))
- [Cutlass] Support bias arg for fp8 GEMM ([#154761](https://github.com/pytorch/pytorch/pull/154761))
- [export] Refactor pt2 save/load ([#152495](https://github.com/pytorch/pytorch/pull/152495))
- [Inductor] Include math and torch in launcher scope ([#154673](https://github.com/pytorch/pytorch/pull/154673))
- Replace runtime type parameterization ([#155221](https://github.com/pytorch/pytorch/pull/155221))
- Add AOTI model name config ([#154129](https://github.com/pytorch/pytorch/pull/154129))
- [Cutlass] Allow filtering by fast_accum for scaled_mm ([#155195](https://github.com/pytorch/pytorch/pull/155195))
- [user triton] mutation analysis for on-device TMA ([#155380](https://github.com/pytorch/pytorch/pull/155380))
- [AOTI] Add int return type support for custom op in proxy executor ([#155465](https://github.com/pytorch/pytorch/pull/155465))
- [Inductor] Limit fusions to a node distance of 64 ([#154688](https://github.com/pytorch/pytorch/pull/154688))
- [Cutlass] Include fp8 headers in aoti cpp wrapper ([#155173](https://github.com/pytorch/pytorch/pull/155173))
- [AOTI] Fix embed_kernel_binary error when max_autotune is ON ([#155569](https://github.com/pytorch/pytorch/pull/155569))
- [inductor][triton pin] add support for new TMA API for mm.py templates ([#155723](https://github.com/pytorch/pytorch/pull/155723))
- unify symbolic_shapes and sizevars dynamic shapes APIs naming 1 ([#154774](https://github.com/pytorch/pytorch/pull/154774))
- [AOTInductor] Memory leak fix for Fallback Kernels ([#155642](https://github.com/pytorch/pytorch/pull/155642))
- basic compile support for grouped_mm ([#153384](https://github.com/pytorch/pytorch/pull/153384))
- [AOTI] Remove the emit_current_arch_binary option ([#155768](https://github.com/pytorch/pytorch/pull/155768))
- [flex attention][triton pin] use new TMA API ([#155771](https://github.com/pytorch/pytorch/pull/155771))
- [inductor] Add configuration control for CUTLASS operation selection. ([#155770](https://github.com/pytorch/pytorch/pull/155770))
- [user triton] JIT inductor support for new host-side TMA api ([#155814](https://github.com/pytorch/pytorch/pull/155814))
- [AOTInductor] Add class declarations to torch._C._aoti interface file ([#155128](https://github.com/pytorch/pytorch/pull/155128))
- [inductor][triton pin] Support triton builtins after #7054 ([#156031](https://github.com/pytorch/pytorch/pull/156031))
- [user triton] AOT Inductor support for new host-side TMA api ([#155879](https://github.com/pytorch/pytorch/pull/155879))
- s/defer_runtime_assert/guard_or_defer_runtime_assert ([#156397](https://github.com/pytorch/pytorch/pull/156397))
- [AOTInductor] Call most runtime fallback ops without calling into Python ([#154142](https://github.com/pytorch/pytorch/pull/154142))
- [aoti] package weights to disk and dedup ([#155241](https://github.com/pytorch/pytorch/pull/155241))
- Support environement var for autotune log ([#156254](https://github.com/pytorch/pytorch/pull/156254))
- Improve torch.ops typing ([#154555](https://github.com/pytorch/pytorch/pull/154555))
- [CUDAGraph] add config `cudagraph_capture_sizes` ([#156551](https://github.com/pytorch/pytorch/pull/156551))
- Add inductor.config.fallback_random which DCEs unused rand calls ([#147790](https://github.com/pytorch/pytorch/pull/147790))
- [2/n][Optimus][Auto-AC] Support activation quantization with scaling ([#151770](https://github.com/pytorch/pytorch/pull/151770))
- Refactor layout constraint selection logic ([#148104](https://github.com/pytorch/pytorch/pull/148104))
### not user facing
- [Inductor][CPP] Fix expr issue in loop split ([#148882](https://github.com/pytorch/pytorch/pull/148882))
- [while_loop] require stride to be the same as input for body_fn ([#148002](https://github.com/pytorch/pytorch/pull/148002))
- skip torchbind in cosntant folding ([#148993](https://github.com/pytorch/pytorch/pull/148993))
- [inductor] Fix issue with set_linter, improve linter framework ([#144620](https://github.com/pytorch/pytorch/pull/144620))
- Fix too big to optimize in test, actually use O0 when aot_inductor.compile_wrapper_with_O0 is set ([#148714](https://github.com/pytorch/pytorch/pull/148714))
- [MPSInductor] Add `bessel_[jy][01]` ops ([#149179](https://github.com/pytorch/pytorch/pull/149179))
- [MPSInductor] Adjust check_bounds ([#147205](https://github.com/pytorch/pytorch/pull/147205))
- [AOTI][debug logger] small fix for intermediate value debugger for jit when arg is not tensor ([#149007](https://github.com/pytorch/pytorch/pull/149007))
- [MPSInductor] Add support for atan2 ([#149216](https://github.com/pytorch/pytorch/pull/149216))
- Not generate custom obj json when it's empty ([#149246](https://github.com/pytorch/pytorch/pull/149246))
- Remove some memory overhead in parallel compile workers ([#149168](https://github.com/pytorch/pytorch/pull/149168))
- [Reland] First version of statically compiled launcher for triton compiled CUDA kernels ([#149238](https://github.com/pytorch/pytorch/pull/149238))
- Fix memory leak in subproc_pool future ([#149259](https://github.com/pytorch/pytorch/pull/149259))
- [mm_logs] make aten mm info readable ([#148800](https://github.com/pytorch/pytorch/pull/148800))
- cpp_wrapper: Precompile device-specific header files ([#146928](https://github.com/pytorch/pytorch/pull/146928))
- fix simple-spec crash ([#147723](https://github.com/pytorch/pytorch/pull/147723))
- [AOTInductor] Add function to free buffer ([#149161](https://github.com/pytorch/pytorch/pull/149161))
- [pt2_provenance_tracking] add support for cpp kernel ([#149185](https://github.com/pytorch/pytorch/pull/149185))
- [MPS/inductor] Add support for `modified_bessel_i1`. ([#149379](https://github.com/pytorch/pytorch/pull/149379))
- Use TorchVersion for triton version check ([#149136](https://github.com/pytorch/pytorch/pull/149136))
- Iterate over dense dim first in split reduction reindexing ([#147229](https://github.com/pytorch/pytorch/pull/147229))
- Fix local compilication and hipification ([#149384](https://github.com/pytorch/pytorch/pull/149384))
- async fx compile ([#146135](https://github.com/pytorch/pytorch/pull/146135))
- [aoti x with_effect token] Unbacked symint and register lowering ([#147656](https://github.com/pytorch/pytorch/pull/147656))
- Fix with effect lowering for list return type ([#149510](https://github.com/pytorch/pytorch/pull/149510))
- Fix score_mod.py dynamic max autotune ([#148991](https://github.com/pytorch/pytorch/pull/148991))
- [MPS/Inductor] Add support for modified_bessel_k0. ([#149593](https://github.com/pytorch/pytorch/pull/149593))
- [Inductor] Fix combo_kernel logging error ([#149575](https://github.com/pytorch/pytorch/pull/149575))
- [AOTI][refactor] Remove dead code ([#149287](https://github.com/pytorch/pytorch/pull/149287))
- [Inductor] Improve memory locality by iterating over y dimension before x ([#149339](https://github.com/pytorch/pytorch/pull/149339))
- Hook StaticCudaLauncher up to torch.compile (cold start) ([#148890](https://github.com/pytorch/pytorch/pull/148890))
- [inductor]lowering scan to while_loop ([#148580](https://github.com/pytorch/pytorch/pull/148580))
- [Inductor Cutlass backend] Fix imports and compilation of Cutlass SM100 Kernels ([#149515](https://github.com/pytorch/pytorch/pull/149515))
- [AOTInductor] Fix skip cpp wrapper unit test ([#149606](https://github.com/pytorch/pytorch/pull/149606))
- [easy] Do not logspam if static cuda launcher is disabled ([#149669](https://github.com/pytorch/pytorch/pull/149669))
- [PT2] Port use_triton_dot_compress to PT2 pre_grad passes ([#148517](https://github.com/pytorch/pytorch/pull/148517))
- [Inductor][CPP] rename shim_mkldnn.h/.cpp to shim_cpu.h/.cpp ([#149372](https://github.com/pytorch/pytorch/pull/149372))
- [Inductor] Unify the data type propagation between Triton and CPP Backend ([#146970](https://github.com/pytorch/pytorch/pull/146970))
- Fakify torchbind objects in compile_fx and add tests for SigridTransformsInstanceTorchBind ([#149529](https://github.com/pytorch/pytorch/pull/149529))
- Make sure to write to caches atomically ([#149654](https://github.com/pytorch/pytorch/pull/149654))
- Cudagraph fix + comment cleanup ([#149741](https://github.com/pytorch/pytorch/pull/149741))
- [PT2] Port use_triton_lce to PT2 pre_grad passes ([#149702](https://github.com/pytorch/pytorch/pull/149702))
- [MPS/inductor] Add support for modified_scaled_bessel_k{0,1} ([#149794](https://github.com/pytorch/pytorch/pull/149794))
- [StaticCudaLauncher] Support any number of kernel arguments ([#149442](https://github.com/pytorch/pytorch/pull/149442))
- [inductor] Add the largest matmul tile size to default tuning set ([#149790](https://github.com/pytorch/pytorch/pull/149790))
- [inductor] fix combo_kernel logging #2 ([#149772](https://github.com/pytorch/pytorch/pull/149772))
- [Inductor-CPU] Fix int8 WoQ AMX micro-kernel when `block_n` is 16 or 48  ([#149359](https://github.com/pytorch/pytorch/pull/149359))
- cpp_wrapper: persist autotune example tensors until last use ([#146706](https://github.com/pytorch/pytorch/pull/146706))
- Use statically known true in should_decompose_mm ([#149950](https://github.com/pytorch/pytorch/pull/149950))
- [MPS/Inductor] Add support for chebyshev_polynomial_t. ([#149928](https://github.com/pytorch/pytorch/pull/149928))
- Support None return type in torchbind and Add more AOTI torchbind e2e tests ([#149749](https://github.com/pytorch/pytorch/pull/149749))
- Reland "Introduce new template heuristic for triton autotune configs" ([#147452](https://github.com/pytorch/pytorch/pull/147452))
- [Inductor] Use real input to autotune user defined triton kernels ([#149553](https://github.com/pytorch/pytorch/pull/149553))
- [MTIA] [Triton] Set codename of MTIA device in triton heuristics ([#149860](https://github.com/pytorch/pytorch/pull/149860))
- [pt2_provenance_tracing] add combo kernel nodes post_grad nodes origin info ([#149598](https://github.com/pytorch/pytorch/pull/149598))
- cache loaded python modules ([#149910](https://github.com/pytorch/pytorch/pull/149910))
- Allow TritonTemplate subclasses to override kernel type ([#150018](https://github.com/pytorch/pytorch/pull/150018))
- meta registration for torch._scaled_mm with mxfp8 ([#148461](https://github.com/pytorch/pytorch/pull/148461))
- [StaticCudaLauncher] Support sharedMemBytes > 48KB ([#149657](https://github.com/pytorch/pytorch/pull/149657))
- Fix autotune pool shutdown ([#149890](https://github.com/pytorch/pytorch/pull/149890))
- dynamo_compile: Log all compilation time under all_compilation_types ([#149664](https://github.com/pytorch/pytorch/pull/149664))
- Ignore meta ops in inductor ([#150137](https://github.com/pytorch/pytorch/pull/150137))
- [inductor] No type promotion for slice_scatter ([#150090](https://github.com/pytorch/pytorch/pull/150090))
- [AOTInductor] Add function for users to extract constants in container ([#150163](https://github.com/pytorch/pytorch/pull/150163))
- [pytorch][triton] Warp specialization support in TritonTemplate for torchinductor (#148503) ([#150122](https://github.com/pytorch/pytorch/pull/150122))
- Move dump location to avoid dumping twice ([#150219](https://github.com/pytorch/pytorch/pull/150219))
- [Inductor] Fix `torch.polygamma()` when n == 1 ([#147453](https://github.com/pytorch/pytorch/pull/147453))
- Fix bug when Inductor include path contains spaces ([#148271](https://github.com/pytorch/pytorch/pull/148271))
- [MPSInductor] Fix neg for unsigned types ([#150412](https://github.com/pytorch/pytorch/pull/150412))
- [ez][inductor][tests] Skip triton backend only for CPU tests ([#150343](https://github.com/pytorch/pytorch/pull/150343))
- [Inductor] Hide reinplace_fsdp_all_gather pass behind skip_fsdp_hooks config ([#150436](https://github.com/pytorch/pytorch/pull/150436))
- [AMD] [TRITON] [INDUCTOR] Add tl.assume to enable bufferops on AMD ([#150373](https://github.com/pytorch/pytorch/pull/150373))
- [MPSInductor] Add `store_reduce` method ([#150457](https://github.com/pytorch/pytorch/pull/150457))
- [CUDAGraph] support meta tensor ([#150478](https://github.com/pytorch/pytorch/pull/150478))
- [AOTI] Emit Triton kernels as comment ([#150188](https://github.com/pytorch/pytorch/pull/150188))
- [Inductor] Reland Merge Triton ScaledMM as epilogue to MM template #150045 ([#150441](https://github.com/pytorch/pytorch/pull/150441))
- Proactively remove CompiledTritonKernels before loading from cache/starting inductor compile ([#150453](https://github.com/pytorch/pytorch/pull/150453))
- [inductor] skip non-trivial tiling if unbacked symints are present ([#150225](https://github.com/pytorch/pytorch/pull/150225))
- Add stride + dtype to autotune results ([#150419](https://github.com/pytorch/pytorch/pull/150419))
- fix bug in logging code ([#150518](https://github.com/pytorch/pytorch/pull/150518))
- [AOTInductor] Fix autotuning code's codegen ([#150522](https://github.com/pytorch/pytorch/pull/150522))
- [Inductor] Cache CUDA compilation errors ([#149716](https://github.com/pytorch/pytorch/pull/149716))
- Make sure torch.compiler._is_compiling_flag=True in aoti ([#150588](https://github.com/pytorch/pytorch/pull/150588))
- [MPS/inductor] Add support for hermite_polynomial_h. ([#150664](https://github.com/pytorch/pytorch/pull/150664))
- [Inductor] Fix consolidating _scaled_mm into mm template TMA error ([#150686](https://github.com/pytorch/pytorch/pull/150686))
- [Inductor] Fallback embedding when sparse is True ([#150659](https://github.com/pytorch/pytorch/pull/150659))
- [MPSInductor] Fix tiled reduction logic ([#150737](https://github.com/pytorch/pytorch/pull/150737))
- cpp_wrapper: Re-enable code disabled for forward compatibility ([#150671](https://github.com/pytorch/pytorch/pull/150671))
- [Inductor] fix alignement assumption for fallback ([#150777](https://github.com/pytorch/pytorch/pull/150777))
- Fill config2launcher with correct launchers during cache hit coordinate descent ([#150860](https://github.com/pytorch/pytorch/pull/150860))
- Hipify global scrach defintion in AOTI codegen ([#150893](https://github.com/pytorch/pytorch/pull/150893))
- [inductor] Add features to docstring_linter (see #142496) ([#145834](https://github.com/pytorch/pytorch/pull/145834))
- [AOTInductor] Add User Managed buffer for AOTI constant buffer. ([#150276](https://github.com/pytorch/pytorch/pull/150276))
- cpp_wrapper: Miscellaneous fixups ([#150143](https://github.com/pytorch/pytorch/pull/150143))
- [Inductor] Remove triton dtype patch which has landed ([#149611](https://github.com/pytorch/pytorch/pull/149611))
- [inductor] Add tests for new docstring_linter features (fix #142496) ([#144621](https://github.com/pytorch/pytorch/pull/144621))
- [inductor] Enable docstring_linter on _inductor ([#144622](https://github.com/pytorch/pytorch/pull/144622))
- [Inductor] assert fallback output alignment ([#150804](https://github.com/pytorch/pytorch/pull/150804))
- Revert two recent prologue prs ([#151013](https://github.com/pytorch/pytorch/pull/151013))
- Don't log benchmarking event to Scuba ([#151053](https://github.com/pytorch/pytorch/pull/151053))
- Add debug_lines of FXGraphCacheKey to AOTAutogradCacheEntry ([#150594](https://github.com/pytorch/pytorch/pull/150594))
- [cutlass backend] Add and fix logs, fix types, and make cutlass generator only generate GEMM ([#150973](https://github.com/pytorch/pytorch/pull/150973))
- [Inductor] Add Subgraph as a Autotuning Choice ([#150653](https://github.com/pytorch/pytorch/pull/150653))
- [graph partition] support graphsafe_run_with_rng_state ([#150958](https://github.com/pytorch/pytorch/pull/150958))
- hack to try to fix not empty triton dir ([#151119](https://github.com/pytorch/pytorch/pull/151119))
- [CI] Fix `GPUTests.test_scheduler_vertical_fusion1` ([#151166](https://github.com/pytorch/pytorch/pull/151166))
- [MPSInductor] Fix noop codegen ([#151224](https://github.com/pytorch/pytorch/pull/151224))
- [MPSInductor] Cast halfs to floats ([#151246](https://github.com/pytorch/pytorch/pull/151246))
- Fix score_mod.py dynamic max autotune for backward ([#151270](https://github.com/pytorch/pytorch/pull/151270))
- [CI] Run test_torchinductor for MPS device ([#150821](https://github.com/pytorch/pytorch/pull/150821))
- improve noop elimination for slice and slice_scatter ([#151175](https://github.com/pytorch/pytorch/pull/151175))
- [inductor][test] Disable Triton GEMM backend tests for SM89 ([#150485](https://github.com/pytorch/pytorch/pull/150485))
- [inductor] disable alignment asserts in fbcode ([#151274](https://github.com/pytorch/pytorch/pull/151274))
- [inductor] Check NoneLayout in update_zero_dim_cpu_tensor ([#151321](https://github.com/pytorch/pytorch/pull/151321))
- [cutlass backend] "Fix" FlexibleLayout ([#151284](https://github.com/pytorch/pytorch/pull/151284))
- [cutlass backend][ez] Ban FP32 output dtype from using CUTLASS GEMM backend ([#151279](https://github.com/pytorch/pytorch/pull/151279))
- [cutlass backend][experimental] Try out presets for cutlass instead of searching all configs ([#151255](https://github.com/pytorch/pytorch/pull/151255))
- [AOTInductor] Add interface for user managed buffer in package api. ([#151325](https://github.com/pytorch/pytorch/pull/151325))
- Fix: missing () in generated runtime assert c++ code ([#151171](https://github.com/pytorch/pytorch/pull/151171))
- [inductor][comms] fix node_summary for composite scheduler nodes ([#150258](https://github.com/pytorch/pytorch/pull/150258))
- [inductor][comms] skip reorder_for_locality for wait nodes ([#150074](https://github.com/pytorch/pytorch/pull/150074))
- [Inductor] Broadcast to range tree shape before block pointer store ([#151399](https://github.com/pytorch/pytorch/pull/151399))
- [invoke_subgraph][inductor] Run pre and post grad passes on invoke_subgraph ([#151330](https://github.com/pytorch/pytorch/pull/151330))
- [inductor] Reduce runtime of CPU OpInfo tests ([#151435](https://github.com/pytorch/pytorch/pull/151435))
- Remove Clear Cache Time from do_bench_using_profiling ([#150696](https://github.com/pytorch/pytorch/pull/150696))
- [Inductor] fix torch._inductor.exc.InductorError: KeyError ([#151424](https://github.com/pytorch/pytorch/pull/151424))
- Include post grad gm and fx runnable in cache artifacts for tlparse ([#151469](https://github.com/pytorch/pytorch/pull/151469))
- [Inductor] Remove singleton tiling splits when prefer_nd_tiling=True ([#151508](https://github.com/pytorch/pytorch/pull/151508))
- Remove libdevice ops in inductor ([#151562](https://github.com/pytorch/pytorch/pull/151562))
- [Inductor] Suppress cuda init error for CPU only Inductor ([#151528](https://github.com/pytorch/pytorch/pull/151528))
- [standalone_compile] Don't check if path is directory if it doesn't exist ([#151501](https://github.com/pytorch/pytorch/pull/151501))
- [standalone_compile] support multiple returns ([#151551](https://github.com/pytorch/pytorch/pull/151551))
- [standalone_compile] Some misc fixes ([#151502](https://github.com/pytorch/pytorch/pull/151502))
- Do not propagate real tensor in extern kernel ([#151377](https://github.com/pytorch/pytorch/pull/151377))
- Add jk for force_disable_caches ([#151621](https://github.com/pytorch/pytorch/pull/151621))
- run lintrunner for Export d68846308 ([#151725](https://github.com/pytorch/pytorch/pull/151725))
- [Inductor] Update should_decompose_mm condition for CPU ([#151730](https://github.com/pytorch/pytorch/pull/151730))
- [pytorch][triton] Enable warp spec for FlexAttention kernel ([#150470](https://github.com/pytorch/pytorch/pull/150470))
- [ez] fix typo in comment ([#151755](https://github.com/pytorch/pytorch/pull/151755))
- Unpack the output code in the standalone_compile ([#151609](https://github.com/pytorch/pytorch/pull/151609))
- Introduce unsafe way to mark functions as cacheable ([#151603](https://github.com/pytorch/pytorch/pull/151603))
- Back out "Do not propagate real tensor in extern kernel" ([#151813](https://github.com/pytorch/pytorch/pull/151813))
- Add explict type info in the try-catch for dynamo logging ([#151733](https://github.com/pytorch/pytorch/pull/151733))
- Lift guard checking logic to AOTAutogradCache ([#151563](https://github.com/pytorch/pytorch/pull/151563))
- [Inductor][FlexAttention] fix `vars_and_sizes` divisor error ([#151634](https://github.com/pytorch/pytorch/pull/151634))
- [provenance_tracking][reland] Fix UT error and re-land `ExternKernel` support ([#151709](https://github.com/pytorch/pytorch/pull/151709))
- More fix for aot_export_module name collision during unlifting ([#151684](https://github.com/pytorch/pytorch/pull/151684))
- [Inductor] move alignment tests to a separate file ([#151841](https://github.com/pytorch/pytorch/pull/151841))
- [MPSInductor] Warn-cast double as floats ([#151963](https://github.com/pytorch/pytorch/pull/151963))
- [Inductor][CPP] Fix Codegen Issue when Parallel Reduction under the vectorization ([#151887](https://github.com/pytorch/pytorch/pull/151887))
- [inductor] handle offset in ReinterpretView for alignment ([#151859](https://github.com/pytorch/pytorch/pull/151859))
- Use /var/tmp instead of /tmp for torch cache directory on fbcode ([#151466](https://github.com/pytorch/pytorch/pull/151466))
- [StandaloneCompile] Autotune at compile time ([#151922](https://github.com/pytorch/pytorch/pull/151922))
- [Inductor] Test ND block pointers with dynamic shapes ([#151646](https://github.com/pytorch/pytorch/pull/151646))
- [cutlass backend] Stop using GenerateSM80 for SM90 and SM100 ([#150781](https://github.com/pytorch/pytorch/pull/150781))
- [pytorch] reland of [cutlass backend] delay construction of cutlass presets to when called (#151875) ([#152031](https://github.com/pytorch/pytorch/pull/152031))
- Better error msg for too big to optimize ([#151855](https://github.com/pytorch/pytorch/pull/151855))
- [Inductor][CPP] Optimize the epilogue for int8 GEMM Template ([#152000](https://github.com/pytorch/pytorch/pull/152000))
- [inductor][BE] Clean up use_mixed_mm and mixed_mm_choice usage inside pytorch ([#152071](https://github.com/pytorch/pytorch/pull/152071))
- Unskip index_put in cudagraphs ([#152186](https://github.com/pytorch/pytorch/pull/152186))
- [logging] Clean up dynamo_timed usages in cudagraph_trees ([#152136](https://github.com/pytorch/pytorch/pull/152136))
- [Indcutor Remote Cache] Raise an exception if redis module is required but not available ([#151779](https://github.com/pytorch/pytorch/pull/151779))
- Check integrity of bytes in AppendingByteSerializer ([#152139](https://github.com/pytorch/pytorch/pull/152139))
- [MPSInductor][BE] Only include headers when needed ([#152266](https://github.com/pytorch/pytorch/pull/152266))
- use statically known true instead of guard size oblivious in bmm and mm inductor decompositions .  ([#148893](https://github.com/pytorch/pytorch/pull/148893))
- [inductor][tests] don't test for cpu if you want to use triton backend ([#152227](https://github.com/pytorch/pytorch/pull/152227))
- [Graph Partition] support ForeachKernelSchedulerNode ([#152148](https://github.com/pytorch/pytorch/pull/152148))
- [Graph Partition] fix extra reference in runner.partitions to cudagraphify functions ([#152066](https://github.com/pytorch/pytorch/pull/152066))
- [inductor][invoke_subgraph] Run joint graph passes for inference ([#152062](https://github.com/pytorch/pytorch/pull/152062))
- [inductor] align `replicationpad` on processing `bool` dtype with eager ([#147666](https://github.com/pytorch/pytorch/pull/147666))
- Add 'step' counter to visualize_overlap log ([#152060](https://github.com/pytorch/pytorch/pull/152060))
- [inductor][fix] enable dtype promotion for bucketize ([#150634](https://github.com/pytorch/pytorch/pull/150634))
- Include CollectiveKernel in inductor debug visualization ([#146561](https://github.com/pytorch/pytorch/pull/146561))
- Add precedence to the infix printing done by sympy_str. ([#151920](https://github.com/pytorch/pytorch/pull/151920))
- [MPSInductor][BE] Make all reductions cacheable ([#152363](https://github.com/pytorch/pytorch/pull/152363))
- [Graph Partition] reorder for minimal number of partitions ([#151968](https://github.com/pytorch/pytorch/pull/151968))
- Refactor TritonTemplate.generate and move codgen part to generate_and_load ([#151764](https://github.com/pytorch/pytorch/pull/151764))
- [MPSInductor] Fix type promotion in `_print_Max` ([#152430](https://github.com/pytorch/pytorch/pull/152430))
- [PT2]: fix add_passes and remove_passes naming issue ([#152386](https://github.com/pytorch/pytorch/pull/152386))
- [Cutlass] Only run EVT tests on sm90 ([#151713](https://github.com/pytorch/pytorch/pull/151713))
- [cutlass backend] Add (limited) bmm dynamic shape support ([#152393](https://github.com/pytorch/pytorch/pull/152393))
- [inductor] Fix usage of launch_enter_hook/launch_exit_hook ([#152457](https://github.com/pytorch/pytorch/pull/152457))
- [inductor][BE] cleanup and improve precompilation loggings ([#152483](https://github.com/pytorch/pytorch/pull/152483))
- [cutlass backend] Add addmm dynamic support ([#152498](https://github.com/pytorch/pytorch/pull/152498))
- [PT2] Port replace_lce_with_matmul / replace_first_lce_with_fused_matmul_lce to PT2 pre_grad passes (#152450) ([#152536](https://github.com/pytorch/pytorch/pull/152536))
- Fix assertion in reorder_communication_preserving_peak_memory ([#152565](https://github.com/pytorch/pytorch/pull/152565))
- [Inductor] Wrapper code refactors to prepare for FX codegen ([#152391](https://github.com/pytorch/pytorch/pull/152391))
- [AOTI][CPU] Introduce config.cpp.use_decompose_tanh ([#152542](https://github.com/pytorch/pytorch/pull/152542))
- Fix constant folding cloning constants ([#152273](https://github.com/pytorch/pytorch/pull/152273))
- [inductor] if unbacked symint in old-size or new-size skip mark_reuse check ([#152379](https://github.com/pytorch/pytorch/pull/152379))
- Fix: Consider input defined unbacked during inductor codegen for runtime asserts ([#152231](https://github.com/pytorch/pytorch/pull/152231))
- [Inductor] Fix kernel argument ordering when using dynamic shapes with workspace ([#152660](https://github.com/pytorch/pytorch/pull/152660))
- Remove incorrect assertion ([#152653](https://github.com/pytorch/pytorch/pull/152653))
- [Inductor][NCU] Add kernel name filtering, and allow custom metrics ([#150872](https://github.com/pytorch/pytorch/pull/150872))
- [reland] Detailed triton kernel logging ([#152694](https://github.com/pytorch/pytorch/pull/152694))
- Implement async manifold cache write ([#152452](https://github.com/pytorch/pytorch/pull/152452))
- Make assertion about pass callable print the bad pass ([#152654](https://github.com/pytorch/pytorch/pull/152654))
- [Autotune Cache] Fix the bug of using the wrong key for recording artifacts in CacheArtifactManager ([#152678](https://github.com/pytorch/pytorch/pull/152678))
- [pytorch][PR][inductor] Fix one instance of launch_enter_hook ([#152831](https://github.com/pytorch/pytorch/pull/152831))
- [inductor] Allow num_program specification for TMA workspace ([#152844](https://github.com/pytorch/pytorch/pull/152844))
- Ensure mxfp8 scaled_mm works w/ max-autotune ([#152744](https://github.com/pytorch/pytorch/pull/152744))
- [inductor][refactor] Refactor the fetching of subgraph names ([#152770](https://github.com/pytorch/pytorch/pull/152770))
- [NFC] [inductor] [compile async] Warn exception if pickler failed ([#152401](https://github.com/pytorch/pytorch/pull/152401))
- [precompile] [easy] Refactor FxGraphCache to add cache_hit_post_compile function ([#152839](https://github.com/pytorch/pytorch/pull/152839))
- [Graph Partition] remove PRECOMPUTED_SIZE from partition symbol inputs ([#152864](https://github.com/pytorch/pytorch/pull/152864))
- [cutlass backend] cache filtered ops based on layouts ([#152580](https://github.com/pytorch/pytorch/pull/152580))
- [Inductor] Set correct baseline for decomposek test ([#152897](https://github.com/pytorch/pytorch/pull/152897))
- [cutlass backend] Skip cuda lib path if it is torch/lib ([#153003](https://github.com/pytorch/pytorch/pull/153003))
- Add torch._C.Tag.needs_contiguous_strides ([#152859](https://github.com/pytorch/pytorch/pull/152859))
- [mm sampling] extract more triton information ([#153099](https://github.com/pytorch/pytorch/pull/153099))
- [cutlass backend] Fix EVT test for fbcode post cutlass 3.9.2 upgrade ([#153106](https://github.com/pytorch/pytorch/pull/153106))
- get right function declaration on windows inductor ([#152939](https://github.com/pytorch/pytorch/pull/152939))
- Keep raw cubin file around in case it gets deleted underneath us ([#153064](https://github.com/pytorch/pytorch/pull/153064))
- [inductor] Fix ModularIndexing assumptions ([#152993](https://github.com/pytorch/pytorch/pull/152993))
- [Graph Partition][Flex Attention] analyze symints from subgraph inputs and outputs ([#152878](https://github.com/pytorch/pytorch/pull/152878))
- [inductor] Generate synthetic offsets appropriately for autotuning _scaled_grouped_mm ([#152968](https://github.com/pytorch/pytorch/pull/152968))
- Refactor nested benchmarking functions in select_algorithm.py ([#153084](https://github.com/pytorch/pytorch/pull/153084))
- Add logging for guard miss failure ([#153125](https://github.com/pytorch/pytorch/pull/153125))
- [Graph Partition] remove weak dep from `partition_input_names` ([#152863](https://github.com/pytorch/pytorch/pull/152863))
- [cutlass-3] Add cutlass key for fbcode and OSS ([#153081](https://github.com/pytorch/pytorch/pull/153081))
- [RFC][inductor] Refactor AlgorithmSelectorCache to spit out make_precompile_fn ([#153212](https://github.com/pytorch/pytorch/pull/153212))
- [inductor] Rename knobs > triton_knobs in static_cuda_launcher ([#153189](https://github.com/pytorch/pytorch/pull/153189))
- [AOTInductor] Add wrapper and kernel code to debug code logging ([#153181](https://github.com/pytorch/pytorch/pull/153181))
- Fix code portability when looking for Dot ([#153259](https://github.com/pytorch/pytorch/pull/153259))
- [cutlass backend] Use src code to generate cutlass gemm name ([#153006](https://github.com/pytorch/pytorch/pull/153006))
- [BE]: Use more portable shutil.which call for cpp_builder ([#153325](https://github.com/pytorch/pytorch/pull/153325))
- [aoti] when generating example input shapes, use unbacked replacements ([#153220](https://github.com/pytorch/pytorch/pull/153220))
- Stop codegen-ing post_grad_custom_pass in repros ([#153243](https://github.com/pytorch/pytorch/pull/153243))
- [Inductor] Optimize grid calculation by using // instead of FloorDiv  ([#153230](https://github.com/pytorch/pytorch/pull/153230))
- [BE]: Use shutil.which in inductor codegen ([#153377](https://github.com/pytorch/pytorch/pull/153377))
- fix bug with TORCHINDUCTOR_DUMP_LAUNCH_PARAMS ([#153066](https://github.com/pytorch/pytorch/pull/153066))
- [cutlass backend] make compile name independent of command ([#153388](https://github.com/pytorch/pytorch/pull/153388))
- Rename "output_tensor" -> "out" in autotune_process.py ([#153169](https://github.com/pytorch/pytorch/pull/153169))
- induct: Log a pt2 compile event + waitcounter for node fusing. ([#153270](https://github.com/pytorch/pytorch/pull/153270))
- Add justknobs for static cuda launcher ([#153400](https://github.com/pytorch/pytorch/pull/153400))
- compile_fx: make a compile event that corresponds to the fx_compile waitcounter ([#152983](https://github.com/pytorch/pytorch/pull/152983))
- Pass inductor config for static cuda launcher to workers ([#153382](https://github.com/pytorch/pytorch/pull/153382))
- [Easy][Inductor] Adds safety checks in get_estimated_runtime ([#152821](https://github.com/pytorch/pytorch/pull/152821))
- [inductor] Use get to avoid possible keyerror at the end of precompilation ([#153417](https://github.com/pytorch/pytorch/pull/153417))
- [cutlass backend] Add back descriptive names for epilogue fusion ([#153405](https://github.com/pytorch/pytorch/pull/153405))
- don't run triton mm for k<32 ([#153550](https://github.com/pytorch/pytorch/pull/153550))
- [pytorch][triton] flex attention fwd kernel with TMA loads (#151923) ([#152460](https://github.com/pytorch/pytorch/pull/152460))
- [cutlass backend] forward fix cutlass backend A100 test ([#153428](https://github.com/pytorch/pytorch/pull/153428))
- [cutlass backend] Reduce log level for cutlass compilation error ([#153397](https://github.com/pytorch/pytorch/pull/153397))
- [Inductor] Fallback bmm to mm when batch == 1 ([#153572](https://github.com/pytorch/pytorch/pull/153572))
- [export] Move PT2 constants to torch::_export ([#153206](https://github.com/pytorch/pytorch/pull/153206))
- [Cutlass] E2E Tests for EVT ([#152815](https://github.com/pytorch/pytorch/pull/152815))
- [inductor] Clean typing in codegen/common.py and codecache.py ([#150767](https://github.com/pytorch/pytorch/pull/150767))
- Change unsafe_marked_cacheable_functions to a dictionary, so that you can specify a static cache key ([#152486](https://github.com/pytorch/pytorch/pull/152486))
- [Inductor] Construct subgraph with benchmarking args not example_inputs ([#153753](https://github.com/pytorch/pytorch/pull/153753))
- [Inductor][XPU] Fallback bmm to mm when batch == 1, align with cuda. ([#153770](https://github.com/pytorch/pytorch/pull/153770))
- [Inductor] Subgraph support dynamic input expressions ([#153754](https://github.com/pytorch/pytorch/pull/153754))
- [Inductor] Subgraph check output strides ([#153755](https://github.com/pytorch/pytorch/pull/153755))
- [cutlass backend] Reduce log level for cutlass runtime error ([#153457](https://github.com/pytorch/pytorch/pull/153457))
- [triton][fb] Move build_paths into triton_utils ([#153652](https://github.com/pytorch/pytorch/pull/153652))
- [inductor] Support cutlass backend with remote execution ([#153844](https://github.com/pytorch/pytorch/pull/153844))
- [Testing] Fix `test_deterministic_`... on MPS ([#153970](https://github.com/pytorch/pytorch/pull/153970))
- Add option to statically launch user defined triton kernels ([#153725](https://github.com/pytorch/pytorch/pull/153725))
- [cutlass backend] Add serializer for cutlass ops ([#153894](https://github.com/pytorch/pytorch/pull/153894))
- [map] add inductor support by lowering to while_loop ([#150971](https://github.com/pytorch/pytorch/pull/150971))
- [ROCm][Inductor][CK] Add ck-tile based universal gemm kernels to torch.mm autotune choices ([#152341](https://github.com/pytorch/pytorch/pull/152341))
- [aoti] fix corner case in unbacked replacements for atomically_apply_size_hint ([#153768](https://github.com/pytorch/pytorch/pull/153768))
- torch.compile: Supress stdout / stderr output from subprocesses when local ([#153837](https://github.com/pytorch/pytorch/pull/153837))
- Move prologue_supported_inputs computations to def_kernal ([#150869](https://github.com/pytorch/pytorch/pull/150869))
- [inductor] Added precompilation_timeout_seconds into a config instead of hardcoded ([#153788](https://github.com/pytorch/pytorch/pull/153788))
- update mutation renames ([#153895](https://github.com/pytorch/pytorch/pull/153895))
- [Cutlass] Use env var for EVT flag ([#154099](https://github.com/pytorch/pytorch/pull/154099))
- Rename the provenance tracing artifact name for kernel <-> post_grad nodes mapping ([#154046](https://github.com/pytorch/pytorch/pull/154046))
- Update provenance tracking doc ([#154062](https://github.com/pytorch/pytorch/pull/154062))
- [Inductor][CPP] Enable vectorized fp8 quant dequant ([#152418](https://github.com/pytorch/pytorch/pull/152418))
- [Inductor][CPP] Enable vectorized fp8 E5M2 quant dequant ([#153365](https://github.com/pytorch/pytorch/pull/153365))
- Make inductor UT to be generic ([#154196](https://github.com/pytorch/pytorch/pull/154196))
- [cutlass backend] Do not raise hard error when re worker has cuda compilation error ([#154173](https://github.com/pytorch/pytorch/pull/154173))
- [Inductor] Allow passing in custom lowering dict to register_lowering() ([#154344](https://github.com/pytorch/pytorch/pull/154344))
- Add a (t * 0) pattern ([#153161](https://github.com/pytorch/pytorch/pull/153161))
- [cutlass backend] small refactor to flatten the ops to avoid nested for loops ([#154576](https://github.com/pytorch/pytorch/pull/154576))
- Reflect back mutation if we clone misaligned tensors ([#154442](https://github.com/pytorch/pytorch/pull/154442))
- Cleanup parent fallback logic ([#154006](https://github.com/pytorch/pytorch/pull/154006))
- [cutlass backend][ez] remove indent for cutlass config serialization ([#154573](https://github.com/pytorch/pytorch/pull/154573))
- [BE][AT] cleanup my old todo ([#154542](https://github.com/pytorch/pytorch/pull/154542))
- [Inductor]Cleanup autotune_fallback_to_aten post-deprecation ([#154331](https://github.com/pytorch/pytorch/pull/154331))
- Add torch.profile benchmarking function to feedback_fns ([#153579](https://github.com/pytorch/pytorch/pull/153579))
- [Inductor] Cache subgraph autotuning choices properly ([#154067](https://github.com/pytorch/pytorch/pull/154067))
- [Inductor] Add envvar to disable decomposeK ([#154421](https://github.com/pytorch/pytorch/pull/154421))
- [cutlass backend] Cache config generation locally and remotely ([#154686](https://github.com/pytorch/pytorch/pull/154686))
- Fix unbackend symint error ([#154672](https://github.com/pytorch/pytorch/pull/154672))
- [Inductor] Record Triton’s Base32 Cache Key in .best_config for Debugging ([#154618](https://github.com/pytorch/pytorch/pull/154618))
- Enable non blocking remote cache write ([#154837](https://github.com/pytorch/pytorch/pull/154837))
- [cutlass backend][ez] Make load config from local more resilient ([#154740](https://github.com/pytorch/pytorch/pull/154740))
- sort iteration over index vars ([#154846](https://github.com/pytorch/pytorch/pull/154846))
- [test][inductor] attempt to fix duplicate registration issue ([#154865](https://github.com/pytorch/pytorch/pull/154865))
- [inductor] Change `_constexpr_to_value` -> `_unwrap_if_constexpr` ([#154905](https://github.com/pytorch/pytorch/pull/154905))
- [cutlass backend][forward fix] hex the cutlass key instead of decode ([#154885](https://github.com/pytorch/pytorch/pull/154885))
- [Graph Partition] support standalone_compile ([#154698](https://github.com/pytorch/pytorch/pull/154698))
- [Tiling rewrite pt1] Normalize reads and writes to common iter space ([#153723](https://github.com/pytorch/pytorch/pull/153723))
- Analyze coalesced mem ([#153730](https://github.com/pytorch/pytorch/pull/153730))
- Solve for tilings ([#153748](https://github.com/pytorch/pytorch/pull/153748))
- [inductor][test] test_padding.py: use inductor TestCase instead of dynamo TestCase ([#154935](https://github.com/pytorch/pytorch/pull/154935))
- [inductor] small cleanups in torch/_inductor/codegen/mps.py ([#154921](https://github.com/pytorch/pytorch/pull/154921))
- [AOTI][Intel GPU] Support multi_arch_kernel_binary option for XPU. ([#154514](https://github.com/pytorch/pytorch/pull/154514))
- Incorporate coalesce analysis in codegen ([#153751](https://github.com/pytorch/pytorch/pull/153751))
- [Inductor] Fix a few FX conversion bugs. ([#154958](https://github.com/pytorch/pytorch/pull/154958))
- [easy] Bump STATIC_CUDA_LAUNCHER_VERSION=1 ([#154861](https://github.com/pytorch/pytorch/pull/154861))
- [PT2][memory] correct wait tensor output size ([#153569](https://github.com/pytorch/pytorch/pull/153569))
- add missing check for caching triton template caching ([#154891](https://github.com/pytorch/pytorch/pull/154891))
- support more prologue functions in generated templates cache ([#154892](https://github.com/pytorch/pytorch/pull/154892))
- support bmm and mm_plus_mm in generated templates cache ([#154904](https://github.com/pytorch/pytorch/pull/154904))
- Handle empty linemaps in PyCodeCache ([#155064](https://github.com/pytorch/pytorch/pull/155064))
- [inductor] disable compiler on the compiled_module_main ([#155169](https://github.com/pytorch/pytorch/pull/155169))
- [BE] minor refactor + some comments on behavior ([#154695](https://github.com/pytorch/pytorch/pull/154695))
- [PT2][comms] put `visualize_overlap` in a try-except block ([#155222](https://github.com/pytorch/pytorch/pull/155222))
- [logs] Add autotuning data ([#154771](https://github.com/pytorch/pytorch/pull/154771))
- [Inductor] Support autotuning in the FX backend. ([#155049](https://github.com/pytorch/pytorch/pull/155049))
- Log backward no-op to tlparse and pt2 compile events. ([#154544](https://github.com/pytorch/pytorch/pull/154544))
- [pt][easy] Rename metadata column ([#155365](https://github.com/pytorch/pytorch/pull/155365))
- Add docblock for autotune_cache.py ([#155133](https://github.com/pytorch/pytorch/pull/155133))
- [ROCm][Inductor][CK] Split ck and ck-tile inductor backend(s) ([#155294](https://github.com/pytorch/pytorch/pull/155294))
- [aoti] Support c10 calls ([#155256](https://github.com/pytorch/pytorch/pull/155256))
- Make require_contiguous require exact strides instead of stride order ([#148424](https://github.com/pytorch/pytorch/pull/148424))
- [invoke_subgraph] Use eager input vals to constrain input strides ([#155291](https://github.com/pytorch/pytorch/pull/155291))
- Apply all replacements on backward graph args during inductor codegen. ([#155469](https://github.com/pytorch/pytorch/pull/155469))
- [Inductor] Set Triton Allocator Function For Use with New TMA API in Inductor ([#155373](https://github.com/pytorch/pytorch/pull/155373))
- [ROCm][Inductor][CK] add kBatch as runtime parameter to CK-tile gemms  ([#155389](https://github.com/pytorch/pytorch/pull/155389))
- [logs] Change autotune data into separate items ([#155525](https://github.com/pytorch/pytorch/pull/155525))
- Revert "[flex attention][triton pin] triton_helpers shim for TMA apis (#154858)" ([#155640](https://github.com/pytorch/pytorch/pull/155640))
- [inductor] Improve GEMM logging to display batch size for batched operations ([#155544](https://github.com/pytorch/pytorch/pull/155544))
- A small fix in do_bench_using_profiling ([#155500](https://github.com/pytorch/pytorch/pull/155500))
- [inductor] handle -1 for pointless view pairs ([#155295](https://github.com/pytorch/pytorch/pull/155295))
- [inductor][invoke_subgraph] Mark invoke_subgraph outputs as user_visible to constrain output strides ([#155395](https://github.com/pytorch/pytorch/pull/155395))
- [cutlass backend] Only consider to use re worker if nvcc doesn't exist ([#155745](https://github.com/pytorch/pytorch/pull/155745))
- [inductor][cutlass backend] Log prescreening elpase ([#155508](https://github.com/pytorch/pytorch/pull/155508))
- Inductor comms reorder logs to tlparse ([#155737](https://github.com/pytorch/pytorch/pull/155737))
- [cutlass backend][ez] Log timings from prescreening ([#155757](https://github.com/pytorch/pytorch/pull/155757))
- Add resolve in add decomp to enable view ([#153945](https://github.com/pytorch/pytorch/pull/153945))
- [BE][1/X] Phase out usage of `use_max_autotune()` ([#155847](https://github.com/pytorch/pytorch/pull/155847))
- Use CUDA language in generated CMakeLists.txt from cpp_builder.py ([#155979](https://github.com/pytorch/pytorch/pull/155979))
- [ez] fix typo in _inductor/scheduler.py ([#155996](https://github.com/pytorch/pytorch/pull/155996))
- [cutlass backend][forward fix] use _cuda_compiler path to check if nvcc exists ([#155939](https://github.com/pytorch/pytorch/pull/155939))
- Add size_hint_or_throw ([#155615](https://github.com/pytorch/pytorch/pull/155615))
- [ez] fix grammar error in comment ([#156053](https://github.com/pytorch/pytorch/pull/156053))
- [BE][4/X] Phase out usage of `use_max_autotune()` ([#155850](https://github.com/pytorch/pytorch/pull/155850))
- [MPSInductor] Improve `_default` dtype inference ([#156121](https://github.com/pytorch/pytorch/pull/156121))
- [cutlass backend] changes how gpu_kernels_o are handled for cutlass ([#155875](https://github.com/pytorch/pytorch/pull/155875))
- [invoke_subgraph][inductor] Dont fallback on complex dtype ([#155885](https://github.com/pytorch/pytorch/pull/155885))
- [BE][3/X] Phase out usage of `use_max_autotune()` ([#155849](https://github.com/pytorch/pytorch/pull/155849))
- [cutlass backend] Fix prescreening non-deterministic problem ([#156144](https://github.com/pytorch/pytorch/pull/156144))
- Skip cache related configs for cache config serialization ([#156195](https://github.com/pytorch/pytorch/pull/156195))
- [ez] rename choice_timings -> choice_timings_fn ([#156099](https://github.com/pytorch/pytorch/pull/156099))
- [BE][2/X] Phase out usage of `use_max_autotune()` ([#155848](https://github.com/pytorch/pytorch/pull/155848))
- [cutlass backend] Add __init__.py to cutlass_lib_extensions ([#156234](https://github.com/pytorch/pytorch/pull/156234))
- [inductor][cutlass] binary remote cache ([#156248](https://github.com/pytorch/pytorch/pull/156248))
- [inductor] Set num_workers to number of available cpu divided by number of available gpu ([#156201](https://github.com/pytorch/pytorch/pull/156201))
- [Inductor][Intel GPU] Support mkldnn Conv post op fusion for XPU. ([#150287](https://github.com/pytorch/pytorch/pull/150287))
- Add logging for async compile worker statistics ([#155820](https://github.com/pytorch/pytorch/pull/155820))
- [Inductor][CPP] Fix WOQ int4 accuracy issue when NC large than one ([#156407](https://github.com/pytorch/pytorch/pull/156407))
- [Inductor] Adjust boundary checking of dimensions using YBLOCK ([#149504](https://github.com/pytorch/pytorch/pull/149504))
- [inductor] force min num-split (off by default) ([#155941](https://github.com/pytorch/pytorch/pull/155941))
- Remove unused MultiKernelCall import from inductor codegen ([#156158](https://github.com/pytorch/pytorch/pull/156158))
- [BE][5/X] Phase out usage of use_max_autotune() ([#156269](https://github.com/pytorch/pytorch/pull/156269))
- [ez] remove unused functions ([#156466](https://github.com/pytorch/pytorch/pull/156466))
- Workaround for e4m2 dtype ([#156461](https://github.com/pytorch/pytorch/pull/156461))
- FlexAttn config refactor + ROCm optimisations ([#156307](https://github.com/pytorch/pytorch/pull/156307))
- Refactor cpp codegen to support overridable class attributes. ([#155553](https://github.com/pytorch/pytorch/pull/155553))
- [easy] better copy_misaligned_inputs assertion failure message ([#154472](https://github.com/pytorch/pytorch/pull/154472))
- [aoti] Check longlong upperbound for codegening input size check ([#156522](https://github.com/pytorch/pytorch/pull/156522))
- [Inductor] Subgraph as a choice symbolic expression as input ([#156185](https://github.com/pytorch/pytorch/pull/156185))
- [Inductor] Allow exhaustive autotuning across all GEMM options ([#156610](https://github.com/pytorch/pytorch/pull/156610))
### security
